For models that do not include within-cluster fixed effects, so that the full covariate matrix is $\bm{U} = \left[\bm{R} \ \bm{S}\right]$, all of the results hold after substituting $\bm{U}$ for $\bm{\ddot{R}}$. 


, finding that specifying the working model in terms of the full regression better maintains the Type-I error of tests based on CR2. 
Thus, we recommend specifying a working model in terms of the full regression, at least when it is computationally feasible to do so. 

We see three disadvantages to specifying the working model in this fashion. First, it depends on an arbitrary choice of which predictors to include in $\bm{R}$ and which to absorb in $\bm{S}$. Second, we find it more difficult to specify a coherent working model for the final-stage regression than for the full regression. 
Finally, the simulation evidence presented in Section \ref{sec:simulation} indicates that ignoring absorption of fixed effects leads to tests that tend to reject at slightly higher rates, which exceed the nominal level under a wider range of conditions than tests constructed under a working model for the full regression. 
Although the differences between these approaches 

Using the more general definition of BRL, the CR2 adjustment matrices should be calculated based on a working model for the errors in the full regression model, following Equations (\ref{eq:CR2_adjustment}) and (\ref{eq:CR2_Bmatrix}) as stated. 




\footnote{ 
\citet{Cameron2015practitioners} highlight that this problem also arises with the CR1S estimator because it uses a multiplicative correction to the residuals that depends on the total number of covariates estimated in the model. 
With the LSDV estimator, the constant is calculated as $c_S = \sqrt{(mN) / [(m - 1)(N - p)]}$, where $p$ is the total number of covariates, including fixed effects. 
In contrast, if the fixed effects are absorbed, the constant is calculated as $c_S = \sqrt{(mN) / [(m - 1)(N - r)]}$, where $r$ is the number of covariates that are not absorbed. 
The difference between the correction factors can be substantial if the clusters are small.}

\footnote{Alternately, for any of the CRVEs one could instead use an ``empirical'' estimate of the degrees of freedom, constructed by substituting $\bm{e}_i \bm{e}_i'$ in place of $\bs\Phi_i$. 
However, \citet{Bell2002bias} found using simulation that this plug-in degrees of freedom estimate led to very conservative rejection rates.}

However, when the degrees of freedom are very small, the t-distribution approximation to the sampling distribution does not hold, and the Type I error can be higher than the stated $\alpha$ level.\footnote{When the degrees of freedom are smaller than 4 or 5, \maskcitet{Tipton2015small-t} suggested using a smaller $\bs\alpha$ level for hypothesis testing in order to partially compensate. Another possibility would be to use the saddlepoint approximation proposed by \citet{McCaffrey2006improved}.}

\footnote{Working in a panel data setting, \citet{Hansen2007asymptotic} and \citet{Donald2007inference} identified conditions under which cluster-robust test statistics converge to a limiting $t$-distribution as the number of measurement occasions increases, holding the number of independent units fixed.}

We further assume that $\left(\bm{U}'\bm{U} - \bm{U}_i'\bm{U}_i\right)$ is of full rank for $i = 1,...,m$.

(However, \citet{Cameron2015practitioners} note that the correction factor used in Stata is sensitive to how the model is estimated, because it is a function of the dimension of the covariate matrix.)

In the $q = 1$ case, the standard is therefore to instead use the t-distribution instead, with degrees of freedom $m - 1$ when CR1 is employed.
Similarly, when $q > 1$, this results in the test $F = Q/q$, which is compared to the $F(q, m - 1)$ reference distribution.
\todo{Is this really standard?} 

By moving to the t and F-distributions, the CR1 corrections greatly improve the performance of these Wald-type tests in small samples.
However, these corrections alone are not adequate, since - like the bias adjustment - the degrees of freedom do not account adequately for features of the covariates that affect performance of the statistics.
Cameron and Miller highlight this problem, noting that the BRL approach provides an alternative method for estimating the degrees of freedom using a Satterthwaite approximation. 
This method has been widely tested and shown to perform well; we review the method and findings in the next sub-section.
Importantly, however, no such small-sample approach has been developed for multi-parameter hypothesist tests. 
In the sub-section that follows, we develop such a test.
Our approach is similar to a Satterthwaite approximation, in that it involves approximating the distribution of $Q$ using an $F$ distribution with estimated degrees of freedom. 

In this section, we review extant work on small-sample corrections for single-parameter hypothesis tests (i.e., t-tests), following which we propose a small-sample correction for multiple-parameter tests (i.e., F-tests).

In addition to the Satterthwaite approximation, two other promising methods for testing single-constraint hypotheses have been proposed. \citet{McCaffrey2006improved} described a saddlepoint approximation to the distribution of $Z$, providing simulation evidence that a test based on a this approximation offers even more accurate rejection rates than the Satterthwaite approximation. 
A further method is to use a bootstrap re-sampling technique that provides small-sample refinements in the test rejection rates.
\citet{Cameron2008bootstrap} studied several such bootstrapping techniques. 
\citet{Webb2013wild} describe a wild boostrap procedure that performs well even when $m$ is quite small and when clusters are of unequal size.  

\cite{Pan2002small} proposed to choose $\eta$ to minimize the squared differences between the covariances among the entries of $\eta \bs\Omega$ and the covariances of the Wishart distribution with $\eta$ degrees of freedom and scale matrix $\bm{C}\bm{V}^{CR}\bm{C}'$. 
\citet{Zhang2012MANOVA} instead matches the mean and total variance of $\bm{C}\bm{V}^{CR}\bm{C}'$ (i.e., the sum of the variances of its entries), which avoids the need to calculate any covariances. 

\citet{McCaffrey2006improved} also found that for single-parameter hypotheses, a saddlepoint approximation to the Wald test statistic provides even more accurate rejection rates than the Satterthwaite approximation given in Equation (\ref{eq:nu_model}). 
It would be interesting to investigate whether the saddlepoint approximation could be extended to handle multiple-parameter constraints, although this appears to be far from straight-forward. 


\section{DISTRIBUTION THEORY FOR $\bm{V}^{CR}$}
\label{app:VCR_dist}

The small-sample approximations for t-tests and F-tests both involve the distribution of the entries of $\bm{V}^{CR2}$. This appendix explains the relevant distribution theory.

% First, note that any of the CR estimators can be written in the form $\bm{V}^{CR2} = \sum_{i=1}^M \bm{P}_i \bm{e}_i \bm{e}_i' \bm{P}_i'$ for $r \times n_i$ matrices $\bm{P}_i = \bm{M_{\ddot{R}}} \bm{\ddot{R}}_i' \bm{W}_i \bm{A}_i$.
% Let $\bm{c}_1,\bm{c}_2,\bm{c}_3,\bm{c}_4$ be fixed, $p \times 1$ vectors and consider the linear combination $\bm{c}_1' \bm{V}^{CR2} \bm{c}_2$. 
% \citet[Theorem 4]{Bell2002bias} show that the linear combination is a quadratic form in $\bm{y}$: \[
% \bm{c}_1' \bm{V}^{CR2} \bm{c}_2 = \bm{y}'\left(\sum_{i=1}^m \bm{p}_{2j} \bm{p}_{1j}'\right) \bm{y}, \]
% for $N \times 1$ vectors $\bm{p}_{sh} = \left(\bm{I} - \bm{H_X}\right)_h' \bm{P}_h' \bm{c}_s$, $s = 1,...,4$, and $h = 1,...,m$. 

Standard results regarding quadratic forms can be used to derive the moments of the linear combination \citep[e.g.,][Sec. 13.5]{Searle2006matrix}. We now assume that $\bs\epsilon_1,...,\bs\epsilon_m$ are multivariate normal with zero mean and variance $\bs\Sigma$. It follows that 
\begin{align}
\label{eq:CRVE_expectation}
\E\left(\bm{c}_1' \bm{V}^{CR2} \bm{c}_2\right) &= \sum_{i=1}^m \bm{p}_{1j}' \bs\Sigma \bm{p}_{2j} \\
\label{eq:CRVE_variance}
\Var\left(\bm{c}_1' \bm{V}^{CR2} \bm{c}_2\right) &= \sum_{i=1}^m \sum_{i=1}^m \left(\bm{p}_{1i}' \bs\Sigma \bm{p}_{2j}\right)^2 + \bm{p}_{1i}' \bs\Sigma \bm{p}_{1j} \bm{p}_{2i}' \bs\Sigma \bm{p}_{2j} \\
\label{eq:CRVE_covariance}
\Cov\left(\bm{c}_1' \bm{V}^{CR2} \bm{c}_2, \bm{c}_3' \bm{V}^{CR} \bm{c}_4\right) &= \sum_{i=1}^m \sum_{i=1}^m \bm{p}_{1i}' \bs\Sigma \bm{p}_{4j} \bm{p}_{2i}' \bs\Sigma \bm{p}_{3j} + \bm{p}_{1i}' \bs\Sigma \bm{p}_{3j} \bm{p}_{2i}' \bs\Sigma \bm{p}_{4j}.
\end{align}
Furthermore, the distribution of $\bm{c}_1' \bm{V}^{CR2} \bm{c}_2$ can be expressed as a weighted sum of $\chi^2_1$ distributions \citep{mathai1992quadratic}, with weights given by the eigen-values of the $m \times m$ matrix with $\left(i,j\right)^{th}$ entry $\bm{p}_{1i}' \bs\Sigma \bm{p}_{2j}$, $i,i=1,...,m$.

% 
% using the CR1 and CR2 adjustments for variance estimation and either the naiv\"e degrees of freedom (for these data, $m - 1 = 34$) or the approximate Hotelling's $T^2$-Z degrees of freedom. 
% Several features of these results are worth noting. 
% First, for the tests of single-parameter hypotheses, the differences between the CR1 and CR2 test statistics are minor, although the AHT (Satterthwaite) degrees of freedom are substantially lower than the naiv\"e ones. 
% As a result, the $p$-value for the ATE in the upper half of the prior achievement distribution is \Sexpr{round(100 * (AL_results[6,"p"] / AL_results[4,"p"] - 1))}\% larger based on our preferred test than based on the standard F-test with CR1. 
% Second, the joint test that the ATEs are zero in both halves of the prior achivement distribution is sensitive to both the CR adjustment and the degrees of freedom: the $p$-value based on our preferred test is \Sexpr{round(AL_results[9,"p"], 3)}, compared to the $p = \Sexpr{round(AL_results[7,"p"], 3)}$ for the standard test. 
% Finally, the test of moderation by sector is strongly affected by the CR2 adjustment and AHT degrees of freedom. 
% In particular, the AHT degrees of freedom are just \Sexpr{round(AL_results[12,"df"],2)}, far lower than the number of clusters. 
% The low degrees of freedom are a consequence of the small number of schools of each type in each treatment condition.
% Although the total sample includes 35 schools, there are only 9 Arab religious, 7 Jewish religious, and 19 Jewish secular schools, each split across two treatment conditions, and the treatment effects are estimated by making comparisons across clusters. 
% As a result, the F statistic based on CR2 has a very large sampling variance under the null hypothesis.
% \todo{Connect to simulation results--higher $q$, between-cluster}

Specifically, we simulated a tri-variate, equi-correlated outcome from a data-generating process in which all three policy conditions produce identical average outcomes, so that all tested null hypotheses hold. 
